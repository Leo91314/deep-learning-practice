{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7d061075d8f1c3c"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-13T13:48:10.477373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "class Inception(nn.Module):\n",
    "    \"\"\"\n",
    "    Inception网络模块，用于深度学习中的多尺度特征提取。\n",
    "    该模块通过四个不同的分支对输入进行并行处理，每个分支负责不同尺度的特征提取，\n",
    "    最后将各个分支的输出合并，形成最终的输出。这种设计使得网络能够同时捕捉到不同尺度\n",
    "    和类型的信息。\n",
    "    参数:\n",
    "    - in_channels: 输入通道数。\n",
    "    - ch1x1: 第一个分支中1x1卷积层的输出通道数。\n",
    "    - ch3x3red: 第二个分支中用于降维的1x1卷积层的输出通道数。\n",
    "    - ch3x3: 第二个分支中3x3卷积层的输出通道数。\n",
    "    - ch5x5red: 第三个分支中用于降维的1x1卷积层的输出通道数。\n",
    "    - ch5x5: 第三个分支中5x5卷积层的输出通道数。\n",
    "    - pool_proj: 第四个分支中用于池化层后降维的1x1卷积层的输出通道数。\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "\n",
    "        self.branch1 = nn.Conv2d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),\n",
    "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),\n",
    "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        return torch.cat([branch1, branch2, branch3, branch4], dim=1)\n",
    "class InceptionAux(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(InceptionAux, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, aux_logits=True):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        if self.aux_logits:\n",
    "            self.aux1 = InceptionAux(512, num_classes)\n",
    "            self.aux2 = InceptionAux(528, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        aux1 = self.aux1(x) if self.aux_logits else None\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        aux2 = self.aux2(x) if self.aux_logits else None\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        if self.aux_logits and self.training:\n",
    "            return x, aux1, aux2\n",
    "        return x\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    trans = [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    transform = transforms.Compose(trans)\n",
    "    mnist_train = datasets.FashionMNIST(root='../data', train=True, transform=transform, download=True)\n",
    "    mnist_test = datasets.FashionMNIST(root='../data', train=False, transform=transform, download=True)\n",
    "    return DataLoader(mnist_train, batch_size=batch_size, shuffle=True), DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # 仅使用主输出计算损失\n",
    "        outputs_main = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "        loss = criterion(outputs_main, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        # 假设 outputs 是 (output_tensor, other_info)\n",
    "        output_tensor = outputs[0]  # 取出第一个元素作为真正的输出\n",
    "        _, predicted = output_tensor.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    acc = 100. * correct / total\n",
    "    print(f'Train Epoch: {epoch} Loss: {avg_loss:.4f} Accuracy: {acc:.2f}%')\n",
    "    return avg_loss, acc\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    acc = 100. * correct / total\n",
    "    print(f'Test Loss: {avg_loss:.4f}, Accuracy: {acc:.2f}%')\n",
    "    return avg_loss, acc\n",
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 20\n",
    "    lr = 0.001\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 调整输入尺寸为 224x224，因为 GoogLeNet 原始设计是用于 ImageNet 的\n",
    "    train_loader, test_loader = load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "    model = GoogLeNet(num_classes=10, aux_logits=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "        test(model, device, test_loader, criterion)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "6561f5131cdad80d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35/469 [04:07<47:08,  6.52s/it]  "
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
